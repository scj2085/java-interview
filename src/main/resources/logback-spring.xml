<?xml version="1.0"?>
<configuration  scan="true" scanPeriod="60 seconds" debug="false">

	<!--Spring Boot为Logback提供了默认的配置文件,base.xml，另外Spring Boot 提供了两个输出端的配置文件console-appender.xml和file-appender.xml，base.xml引用了这两个配置文件 -->
	<include resource="org/springframework/boot/logging/logback/base.xml"/>
	<!-- 定义日志文件 输入位置 ,/logs本项目所在的磁盘根目录-->
<!--     <property name="LOG_HOME" value="/logs"/>   -->
    <!-- 日志最大的历史 30天 -->  
    <property name="maxHistory" value="30"/>
	
	<!-- ch.qos.logback.core.ConsoleAppender 控制台输出 -->
	<appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">  
	    <filter class="ch.qos.logback.classic.filter.LevelFilter">  
	      <level>INFO</level>  
	      <onMatch>ACCEPT</onMatch>  
	      <onMismatch>DENY</onMismatch>  
	    </filter>  
	    <encoder>  
	      <pattern>  
	        %-4relative [%thread] %-5level %logger{30} - %msg%n  
	      </pattern>  
	    </encoder>  
  	</appender>
<!-- 	<appender name="console" class="ch.qos.logback.core.ConsoleAppender"> -->
		<!-- 对日志进行格式化 -->
<!-- 		<encoder> -->
		<!-- 格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符  -->
<!-- 			<pattern>[%-5level] [%thread] %X{client} %X{trace_id} %d{HH:mm:ss} %logger => %msg%n</pattern> -->
<!-- 		</encoder> -->
<!-- 	</appender> -->

	<!-- 系统 日志记录器，日期滚动记录 -->
	<appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender">
<!-- 		 正在记录的日志文件的路径及文件名 --> 
		<File>${LOG_PATH}/interview-system.log</File>
<!-- 		 日志记录器的滚动策略，按日期，按大小记录 --> 
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
<!-- 			 归档的日志文件的路径，例如今天是2013-12-21日志，当前写的日志文件路径为file节点指定，可以将此文件与file指定文件路径设置为不同路径，从而将当前日志文件或归档日志文件置不同的目录。 -->
<!--            		 而2013-12-21的日志文件在由fileNamePattern指定。%d{yyyy-MM-dd}指定日期格式，%i指定索引 --> 
			<FileNamePattern>${LOG_PATH}/interview-system-%d{yyyy-MM-dd}.%i.log</FileNamePattern>
<!-- 			 除按日志记录之外，还配置了日志文件不能超过2M，若超过2M，日志文件会以索引0开始， -->
<!--            	 命名日志文件，例如log-error-2013-12-21.0.log --> 
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>2MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
<!--         追加方式记录日志 -->
        <append>true</append>
		
		<layout class="ch.qos.logback.classic.PatternLayout">
<!-- 			格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--> 
			<pattern>[%-5level] [%thread] %X{client} %X{trace_id} %d{HH:mm:ss} %logger{36} => %msg%n</pattern>
		</layout>
	</appender>
	
	<!-- 操作记录日志文件 -->
	<appender name="file-error"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 正在记录的日志文件的路径及文件名 -->
		<File>${LOG_PATH}/interview-error-temporary.log</File>
<!-- 		 过滤器，只记录WARN级别的日志 -->
		<filter class="ch.qos.logback.classic.filter.LevelFilter">  
	      <level>ERROR</level>  
	      <onMatch>ACCEPT</onMatch>  
	      <onMismatch>DENY</onMismatch>  
	    </filter>
		<!-- 日志记录器的滚动策略，按日期，按大小记录 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<!-- 归档的日志文件的路径，例如今天是2013-12-21日志，当前写的日志文件路径为file节点指定，可以将此文件与file指定文件路径设置为不同路径，从而将当前日志文件或归档日志文件置不同的目录。
           		 而2013-12-21的日志文件在由fileNamePattern指定。%d{yyyy-MM-dd}指定日期格式，%i指定索引 -->
			<FileNamePattern>${LOG_PATH}/interview-error-pigeonhole-%d{yyyy-MM-dd}.%i.log</FileNamePattern>
			<!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件假设设置每个月滚动，且<maxHistory>是6，   则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除-->  
<!--             <maxHistory>${maxHistory}</maxHistory> -->
			<!-- 除按日志记录之外，还配置了日志文件不能超过2M，若超过2M，日志文件会以索引0开始，
           	 命名日志文件，例如log-error-2013-12-21.0.log -->
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>2MB</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		   <!-- 按照固定窗口模式生成日志文件，当文件大于20MB时，生成新的日志文件。窗口大小是1到3，当保存了3个归档文件后，将覆盖最早的日志。  --> 
<!--         <rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy">      -->
<!--           <fileNamePattern>${log_dir}/%d{yyyy-MM-dd}/.log.zip</fileNamePattern>      -->
<!--           <minIndex>1</minIndex>      -->
<!--           <maxIndex>3</maxIndex>      -->
<!--         </rollingPolicy>   -->
<!--         查看当前活动文件的大小，如果超过指定大小会告知RollingFileAppender 触发当前活动文件滚动    -->
        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">     
            <maxFileSize>5MB</maxFileSize>     
        </triggeringPolicy>  
		<layout class="ch.qos.logback.classic.PatternLayout">
<!-- 			 对日志进行格式化  -->
			<pattern>[%-5level] [%thread] %X{client} %X{trace_id} %d{HH:mm:ss} %logger{36} => %msg%n</pattern>
		</layout>
	</appender>
	
	<!-- WARN级别日志 appender -->  
    <appender name="warn" class="ch.qos.logback.core.rolling.RollingFileAppender">  
    	<!-- 正在记录的日志文件的路径及文件名 -->
		<File>${LOG_PATH}/interview-warn-temporary.log</File>
<!--         过滤器，只记录WARN级别的日志   -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">  
	      <level>WARN</level>  
	      <onMatch>ACCEPT</onMatch>  
	      <onMismatch>DENY</onMismatch>  
	    </filter>  
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">  
<!--             按天回滚 daily   -->
            <fileNamePattern>${LOG_HOME}/interview-warn-pigeonhole-%d{yyyy-MM-dd}.%i.log  
            </fileNamePattern>  
<!--             日志最大的历史 60天   -->
            <maxHistory>${maxHistory}</maxHistory>  
        </rollingPolicy>  
        <encoder>  
<!--        对日志进行格式化 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n</pattern>  
        </encoder>  
    </appender>
	
	<!-- DEBUG级别日志 appender -->
	<appender name="file-debug" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<File>${LOG_PATH}/interview-debug-temporary.log</File>
<!-- 		 过滤器，只记录DEBUG级别的日志 --> 
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>DEBUG</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">  
<!--              按天回滚 daily    -->
            <fileNamePattern>${LOG_HOME}/interview-debug-pigeonhole-%d{yyyy-MM-dd}.%i.log  
            </fileNamePattern>  
<!--             日志最大的历史 60天   -->
            <maxHistory>${maxHistory}</maxHistory>  
        </rollingPolicy>
		<encoder>
<!-- 	对日志进行格式化  -->
			<pattern>[%-5level] [%thread] %X{client} %X{trace_id} %d{HH:mm:ss} %logger{36} => %msg%n</pattern>
		</encoder>
	</appender>
	
	<appender name="file-msg" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<File>${LOG_PATH}/interview-info-temporary.log</File>
<!-- 		 过滤器，只记录INFO级别的日志 --> 
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>INFO</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">  
<!--             按天回滚 daily   -->
            <fileNamePattern>${log_dir}/interview-info-pigeonhole-%d{yyyy-MM-dd}.%i.log  
            </fileNamePattern>  
<!--             日志最大的历史 60天   -->
            <maxHistory>${maxHistory}</maxHistory>  
        </rollingPolicy>
		<encoder>
			<pattern>%msg%n</pattern>
		</encoder>
	</appender>
  
<!-- 	<root level="info">   -->
	<root level="DEBUG">  
		<appender-ref ref="CONSOLE" />  
		<appender-ref ref="file" />  
		<appender-ref ref="file-error" />  
		<appender-ref ref="warn" />  
		<appender-ref ref="file-debug" />  
		<appender-ref ref="file-msg" />  
	</root>

	<!-- 3rdparty Loggers -->
	<logger name="org.springframework.core" level="info"/>
	<logger name="org.springframework.beans" level="info"/>
	<logger name="org.springframework.context" level="info"/>
	<logger name="org.springframework.web" level="info"/>
	<logger name="org.springframework.web.filter.CommonsRequestLoggingFilter" level="DEBUG"/>
	<logger name="org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor" level="DEBUG"/>
	<logger name="org.springframework.boot" level="info" />
	<logger name="org.springframework.aop" level="info" />
	<logger name="org.springframework.jmx" level="info" />
	<logger name="org.springframework.jdbc" level="info" />
	<logger name="org.springframework.transaction" level="info" />
	<logger name="ch.qos.logback" level="ERROR" />
<!-- 	<logger name="org.activiti" level="info" /> -->
<!-- 	<logger name="org.hibernate.validator" level="info" /> -->
	<logger name="org.apache.shiro" level="info"/>
	<logger name="org.apache.ibatis" level="info"/>
	<logger name="org.mybatis" level="info"/>
    <logger name="java.sql.Connection" level="DEBUG"/>
    <logger name="java.sql.Statement" level="DEBUG"/>
    <logger name="java.sql.PreparedStatement" level="DEBUG"/>
    
    <!-- 	<springProfile name="dev"> -->
<!--  		additivity="false"如果为true，会打印两次, 因为root会打印一次-->
<!-- 		<logger name="com.juntai.juntai_rms.manager.AccountManager" additivity="false" level="info"> -->
<!-- 	        <appender-ref ref="file-msg" /> -->
<!-- 	    </logger> -->
<!-- 	    <logger name="com.gomeplus.meipro.uc.service.impl.UserService" additivity="false" level="info"> -->
<!-- 	        <appender-ref ref="file-msg" /> -->
<!-- 	    </logger> -->
<!-- 	</springProfile>  -->
<!-- 	<springProfile name="pre-product"> -->
<!-- 		<logger name="com.gomeplus.meipro.uc.service.impl.StaffInviteService" additivity="false" level="info"> -->
<!-- 	        <appender-ref ref="file-msg" /> -->
<!-- 	    </logger> -->
<!-- 	    <logger name="com.gomeplus.meipro.uc.service.impl.UserService" additivity="false" level="info"> -->
<!-- 	        <appender-ref ref="file-msg" /> -->
<!-- 	    </logger> -->
<!-- 	</springProfile> -->
	
	 <!--日志异步到数据库 -->  
<!--     <appender name="DB" class="ch.qos.logback.classic.db.DBAppender"> -->
<!--         日志异步到数据库  -->
<!--         <connectionSource class="ch.qos.logback.core.db.DriverManagerConnectionSource"> -->
<!--            连接池  -->
<!--            <dataSource class="com.mchange.v2.c3p0.ComboPooledDataSource"> -->
<!--               <driverClass>com.mysql.jdbc.Driver</driverClass> -->
<!--               <url>jdbc:mysql://127.0.0.1:3306/databaseName</url> -->
<!--               <user>root</user> -->
<!--               <password>root</password> -->
<!--             </dataSource> -->
<!--         </connectionSource> -->
<!--   	</appender>  -->
	
</configuration>